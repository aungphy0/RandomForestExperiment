{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "described-person",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"font-size:2vw;\">\n",
    "       CSC 859 AI Explainability and Ethics <br> <br>\n",
    "       San Francisco State University <br> <br>\n",
    "       Fall 2023 <br> <br>\n",
    "       Aung Phyo <br> <br>\n",
    "       Oct 30 2023 <br> <br>\n",
    "       HW 2\n",
    "<div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "specified-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-trademark",
   "metadata": {},
   "source": [
    "# <center> Audit of Training database </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-marijuana",
   "metadata": {},
   "source": [
    "The training dataset is real data from a biological study. \n",
    "\n",
    "The dataset has 871 samples 608 features and 1 target label which is binary 1 for positive result and 0 for negative result. \n",
    "\n",
    "All the features columns are numerical and there are no missing data. There is 0.0 value in the features columns \n",
    "but it is the actual value and not a missing value. Using the forloop to check the missing data in the dataset, if there are showing True in the dataset, there are missing data. Since, the dataset does not have missing data and all the features columns of the missing data checking values are False. \n",
    "\n",
    "There are 781 of 0 label samples and 90 of 1 label samples in the dataset. \n",
    "\n",
    "Reference to data source : \n",
    "\"Aevermann B., Novotny M., Bakken T., Miller J., Diehl A., Osumi-Sutherland D.,\n",
    "Lasken R., Lein E., Scheuermann R.: “Cell type discovery using single cell\n",
    "transcriptomics: implications for ontological representation”, Human Molecular Genetics\n",
    "27(R1): R40-R47 · March 2018\"\n",
    "\n",
    "[Link to the reference to data source](https://academic.oup.com/hmg/article/27/R1/R40/4953379)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "literary-clearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871, 609)\n",
      "Number of samples:  871\n",
      "Number of features:  608\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GABRG2</th>\n",
       "      <th>CELF4</th>\n",
       "      <th>SRRM4</th>\n",
       "      <th>SLC1A3</th>\n",
       "      <th>ATP1A3</th>\n",
       "      <th>RBFOX3</th>\n",
       "      <th>GABRA4</th>\n",
       "      <th>NHSL1</th>\n",
       "      <th>GRAMD3</th>\n",
       "      <th>SEZ6L2</th>\n",
       "      <th>...</th>\n",
       "      <th>FERMT1</th>\n",
       "      <th>CSPG4</th>\n",
       "      <th>GJA1</th>\n",
       "      <th>LAMA1</th>\n",
       "      <th>YAP1</th>\n",
       "      <th>LINC00639.2</th>\n",
       "      <th>SMOC1</th>\n",
       "      <th>LINC00498</th>\n",
       "      <th>GFRA1</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.038262</td>\n",
       "      <td>161.176004</td>\n",
       "      <td>68.074337</td>\n",
       "      <td>58.063405</td>\n",
       "      <td>20.021864</td>\n",
       "      <td>269.294069</td>\n",
       "      <td>188.205520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.001093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.324867</td>\n",
       "      <td>75.256474</td>\n",
       "      <td>87.297510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.061554</td>\n",
       "      <td>342.166102</td>\n",
       "      <td>683.328784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.003420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.003420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220.143867</td>\n",
       "      <td>187.976727</td>\n",
       "      <td>42.219372</td>\n",
       "      <td>106.553653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>187.976727</td>\n",
       "      <td>299.556496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.036562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>166.010840</td>\n",
       "      <td>26.159284</td>\n",
       "      <td>61.373704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.183789</td>\n",
       "      <td>254.549955</td>\n",
       "      <td>446.720079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.153158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.006126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188.426220</td>\n",
       "      <td>71.160966</td>\n",
       "      <td>119.269788</td>\n",
       "      <td>57.129226</td>\n",
       "      <td>16.036274</td>\n",
       "      <td>265.600789</td>\n",
       "      <td>287.650666</td>\n",
       "      <td>24.054411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.002267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 609 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GABRG2       CELF4       SRRM4      SLC1A3     ATP1A3      RBFOX3  \\\n",
       "0   35.038262  161.176004   68.074337   58.063405  20.021864  269.294069   \n",
       "1   95.324867   75.256474   87.297510    0.000000  18.061554  342.166102   \n",
       "2  220.143867  187.976727   42.219372  106.553653   0.000000  187.976727   \n",
       "3  166.010840   26.159284   61.373704    0.000000  30.183789  254.549955   \n",
       "4  188.426220   71.160966  119.269788   57.129226  16.036274  265.600789   \n",
       "\n",
       "       GABRA4      NHSL1  GRAMD3     SEZ6L2  ...  FERMT1  CSPG4  GJA1  LAMA1  \\\n",
       "0  188.205520   0.000000     0.0   0.000000  ...     0.0    0.0   0.0    0.0   \n",
       "1  683.328784   0.000000     0.0   1.003420  ...     0.0    0.0   0.0    0.0   \n",
       "2  299.556496   0.000000     0.0   0.000000  ...     0.0    0.0   0.0    0.0   \n",
       "3  446.720079   0.000000     0.0  25.153158  ...     0.0    0.0   0.0    0.0   \n",
       "4  287.650666  24.054411     0.0   1.002267  ...     0.0    0.0   0.0    0.0   \n",
       "\n",
       "   YAP1  LINC00639.2     SMOC1  LINC00498  GFRA1  Label  \n",
       "0   0.0     0.000000  1.001093        0.0    0.0      0  \n",
       "1   0.0     0.000000  1.003420        0.0    0.0      0  \n",
       "2   0.0     7.036562  0.000000        0.0    0.0      0  \n",
       "3   0.0     0.000000  1.006126        0.0    0.0      0  \n",
       "4   0.0     0.000000  0.000000        0.0    0.0      0  \n",
       "\n",
       "[5 rows x 609 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./i1_positive.csv')\n",
    "\n",
    "print(data.shape)\n",
    "print(\"Number of samples: \", data.shape[0])\n",
    "print(\"Number of features: \", data.shape[1]-1)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "outer-survey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GABRG2</th>\n",
       "      <th>CELF4</th>\n",
       "      <th>SRRM4</th>\n",
       "      <th>SLC1A3</th>\n",
       "      <th>ATP1A3</th>\n",
       "      <th>RBFOX3</th>\n",
       "      <th>GABRA4</th>\n",
       "      <th>NHSL1</th>\n",
       "      <th>GRAMD3</th>\n",
       "      <th>SEZ6L2</th>\n",
       "      <th>...</th>\n",
       "      <th>FERMT1</th>\n",
       "      <th>CSPG4</th>\n",
       "      <th>GJA1</th>\n",
       "      <th>LAMA1</th>\n",
       "      <th>YAP1</th>\n",
       "      <th>LINC00639.2</th>\n",
       "      <th>SMOC1</th>\n",
       "      <th>LINC00498</th>\n",
       "      <th>GFRA1</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>871 rows × 609 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GABRG2  CELF4  SRRM4  SLC1A3  ATP1A3  RBFOX3  GABRA4  NHSL1  GRAMD3  \\\n",
       "0     False  False  False   False   False   False   False  False   False   \n",
       "1     False  False  False   False   False   False   False  False   False   \n",
       "2     False  False  False   False   False   False   False  False   False   \n",
       "3     False  False  False   False   False   False   False  False   False   \n",
       "4     False  False  False   False   False   False   False  False   False   \n",
       "..      ...    ...    ...     ...     ...     ...     ...    ...     ...   \n",
       "866   False  False  False   False   False   False   False  False   False   \n",
       "867   False  False  False   False   False   False   False  False   False   \n",
       "868   False  False  False   False   False   False   False  False   False   \n",
       "869   False  False  False   False   False   False   False  False   False   \n",
       "870   False  False  False   False   False   False   False  False   False   \n",
       "\n",
       "     SEZ6L2  ...  FERMT1  CSPG4   GJA1  LAMA1   YAP1  LINC00639.2  SMOC1  \\\n",
       "0     False  ...   False  False  False  False  False        False  False   \n",
       "1     False  ...   False  False  False  False  False        False  False   \n",
       "2     False  ...   False  False  False  False  False        False  False   \n",
       "3     False  ...   False  False  False  False  False        False  False   \n",
       "4     False  ...   False  False  False  False  False        False  False   \n",
       "..      ...  ...     ...    ...    ...    ...    ...          ...    ...   \n",
       "866   False  ...   False  False  False  False  False        False  False   \n",
       "867   False  ...   False  False  False  False  False        False  False   \n",
       "868   False  ...   False  False  False  False  False        False  False   \n",
       "869   False  ...   False  False  False  False  False        False  False   \n",
       "870   False  ...   False  False  False  False  False        False  False   \n",
       "\n",
       "     LINC00498  GFRA1  Label  \n",
       "0        False  False  False  \n",
       "1        False  False  False  \n",
       "2        False  False  False  \n",
       "3        False  False  False  \n",
       "4        False  False  False  \n",
       "..         ...    ...    ...  \n",
       "866      False  False  False  \n",
       "867      False  False  False  \n",
       "868      False  False  False  \n",
       "869      False  False  False  \n",
       "870      False  False  False  \n",
       "\n",
       "[871 rows x 609 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "still-illinois",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no missing data!\n"
     ]
    }
   ],
   "source": [
    "missing_data = data.isnull()\n",
    "\n",
    "for column in missing_data.columns.values.tolist():\n",
    "    if 'True' in column:\n",
    "        print(column)\n",
    "        print(missing_data[column].value_counts())\n",
    "        print(\"\")\n",
    "print(\"no missing data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "electrical-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 label samples :  781\n",
      "1 label samples :  90\n"
     ]
    }
   ],
   "source": [
    "label_list = data['Label'].value_counts().tolist()\n",
    "\n",
    "print(\"0 label samples : \", label_list[0])\n",
    "print(\"1 label samples : \", label_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rubber-freeware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GABRG2</th>\n",
       "      <th>CELF4</th>\n",
       "      <th>SRRM4</th>\n",
       "      <th>SLC1A3</th>\n",
       "      <th>ATP1A3</th>\n",
       "      <th>RBFOX3</th>\n",
       "      <th>GABRA4</th>\n",
       "      <th>NHSL1</th>\n",
       "      <th>GRAMD3</th>\n",
       "      <th>SEZ6L2</th>\n",
       "      <th>...</th>\n",
       "      <th>FERMT1</th>\n",
       "      <th>CSPG4</th>\n",
       "      <th>GJA1</th>\n",
       "      <th>LAMA1</th>\n",
       "      <th>YAP1</th>\n",
       "      <th>LINC00639.2</th>\n",
       "      <th>SMOC1</th>\n",
       "      <th>LINC00498</th>\n",
       "      <th>GFRA1</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>871.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>317.195147</td>\n",
       "      <td>160.794717</td>\n",
       "      <td>188.372969</td>\n",
       "      <td>263.524808</td>\n",
       "      <td>79.262833</td>\n",
       "      <td>137.275239</td>\n",
       "      <td>229.995772</td>\n",
       "      <td>52.507171</td>\n",
       "      <td>59.435549</td>\n",
       "      <td>41.151089</td>\n",
       "      <td>...</td>\n",
       "      <td>10.664136</td>\n",
       "      <td>2.557719</td>\n",
       "      <td>31.528201</td>\n",
       "      <td>14.410798</td>\n",
       "      <td>11.514892</td>\n",
       "      <td>7.873938</td>\n",
       "      <td>24.349328</td>\n",
       "      <td>4.727715</td>\n",
       "      <td>4.940665</td>\n",
       "      <td>0.103330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>378.241239</td>\n",
       "      <td>189.064895</td>\n",
       "      <td>208.232294</td>\n",
       "      <td>999.259112</td>\n",
       "      <td>127.012517</td>\n",
       "      <td>264.213953</td>\n",
       "      <td>245.183809</td>\n",
       "      <td>232.926742</td>\n",
       "      <td>291.806179</td>\n",
       "      <td>80.825275</td>\n",
       "      <td>...</td>\n",
       "      <td>99.005377</td>\n",
       "      <td>29.264949</td>\n",
       "      <td>221.308620</td>\n",
       "      <td>91.880695</td>\n",
       "      <td>81.364902</td>\n",
       "      <td>79.936480</td>\n",
       "      <td>113.287913</td>\n",
       "      <td>37.848376</td>\n",
       "      <td>32.248300</td>\n",
       "      <td>0.304564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38.894340</td>\n",
       "      <td>32.084673</td>\n",
       "      <td>35.094833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.019327</td>\n",
       "      <td>14.288171</td>\n",
       "      <td>33.733073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.001922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>218.427681</td>\n",
       "      <td>108.811797</td>\n",
       "      <td>130.794368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.073964</td>\n",
       "      <td>73.962624</td>\n",
       "      <td>181.287669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.080387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>440.087971</td>\n",
       "      <td>218.480061</td>\n",
       "      <td>265.911406</td>\n",
       "      <td>6.031598</td>\n",
       "      <td>100.142130</td>\n",
       "      <td>169.816497</td>\n",
       "      <td>334.398305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.005632</td>\n",
       "      <td>47.306796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.014025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3435.333490</td>\n",
       "      <td>2011.629811</td>\n",
       "      <td>1704.202638</td>\n",
       "      <td>10950.762140</td>\n",
       "      <td>1293.563390</td>\n",
       "      <td>6061.307927</td>\n",
       "      <td>2058.199518</td>\n",
       "      <td>2331.740949</td>\n",
       "      <td>4900.202343</td>\n",
       "      <td>839.058368</td>\n",
       "      <td>...</td>\n",
       "      <td>2086.435931</td>\n",
       "      <td>685.510866</td>\n",
       "      <td>3557.887531</td>\n",
       "      <td>1486.017423</td>\n",
       "      <td>1660.938508</td>\n",
       "      <td>1949.849508</td>\n",
       "      <td>2147.133231</td>\n",
       "      <td>513.075890</td>\n",
       "      <td>530.991217</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 609 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            GABRG2        CELF4        SRRM4        SLC1A3       ATP1A3  \\\n",
       "count   871.000000   871.000000   871.000000    871.000000   871.000000   \n",
       "mean    317.195147   160.794717   188.372969    263.524808    79.262833   \n",
       "std     378.241239   189.064895   208.232294    999.259112   127.012517   \n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "25%      38.894340    32.084673    35.094833      0.000000     4.019327   \n",
       "50%     218.427681   108.811797   130.794368      0.000000    29.073964   \n",
       "75%     440.087971   218.480061   265.911406      6.031598   100.142130   \n",
       "max    3435.333490  2011.629811  1704.202638  10950.762140  1293.563390   \n",
       "\n",
       "            RBFOX3       GABRA4        NHSL1       GRAMD3      SEZ6L2  ...  \\\n",
       "count   871.000000   871.000000   871.000000   871.000000  871.000000  ...   \n",
       "mean    137.275239   229.995772    52.507171    59.435549   41.151089  ...   \n",
       "std     264.213953   245.183809   232.926742   291.806179   80.825275  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000    0.000000  ...   \n",
       "25%      14.288171    33.733073     0.000000     0.000000    1.001922  ...   \n",
       "50%      73.962624   181.287669     0.000000     0.000000    5.080387  ...   \n",
       "75%     169.816497   334.398305     0.000000     1.005632   47.306796  ...   \n",
       "max    6061.307927  2058.199518  2331.740949  4900.202343  839.058368  ...   \n",
       "\n",
       "            FERMT1       CSPG4         GJA1        LAMA1         YAP1  \\\n",
       "count   871.000000  871.000000   871.000000   871.000000   871.000000   \n",
       "mean     10.664136    2.557719    31.528201    14.410798    11.514892   \n",
       "std      99.005377   29.264949   221.308620    91.880695    81.364902   \n",
       "min       0.000000    0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000    0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000    0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000    0.000000     0.000000     0.000000     0.000000   \n",
       "max    2086.435931  685.510866  3557.887531  1486.017423  1660.938508   \n",
       "\n",
       "       LINC00639.2        SMOC1   LINC00498       GFRA1       Label  \n",
       "count   871.000000   871.000000  871.000000  871.000000  871.000000  \n",
       "mean      7.873938    24.349328    4.727715    4.940665    0.103330  \n",
       "std      79.936480   113.287913   37.848376   32.248300    0.304564  \n",
       "min       0.000000     0.000000    0.000000    0.000000    0.000000  \n",
       "25%       0.000000     0.000000    0.000000    0.000000    0.000000  \n",
       "50%       0.000000     0.000000    0.000000    0.000000    0.000000  \n",
       "75%       0.000000     1.014025    0.000000    0.000000    0.000000  \n",
       "max    1949.849508  2147.133231  513.075890  530.991217    1.000000  \n",
       "\n",
       "[8 rows x 609 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-adolescent",
   "metadata": {},
   "source": [
    "# <center> SW tools </center>\n",
    "\n",
    "The software tools that I used for the project are : \n",
    "\n",
    "* jupyter notebook for software running environment and text documentation <br><br>\n",
    "\n",
    "* python programming language <br><br>\n",
    "\n",
    "* pandas python library to transform the dataset into the data frame <br><br>\n",
    "\n",
    "* numpy python library for numerical, and basic statistics calculation <br><br>\n",
    "\n",
    "* scikit-learn python library for the machine learning models <br><br>\n",
    "\n",
    "* matplotlib to show the plot, graph and visualization <br><br>\n",
    "\n",
    "\n",
    "For the data processing, I separated the features columns and class label columns. The dataset has label which is the class label either 0 or 1. Fearutes columns are all the columns except the label and all have the numerical data and there are no missing values.  \n",
    "\n",
    "The reason for separating the features columns and the label is to split the dataset to train and test the machine learning model. In this project, I am going to use the Random Forest Classification machine learning model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "powered-thailand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871, 608)\n",
      "(871,)\n",
      "608\n"
     ]
    }
   ],
   "source": [
    "features = data.drop(columns=[\"Label\"])\n",
    "Y = data[\"Label\"]\n",
    "\n",
    "print(features.shape)\n",
    "print(Y.shape)\n",
    "print(len(features.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "public-rover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GABRG2</th>\n",
       "      <th>CELF4</th>\n",
       "      <th>SRRM4</th>\n",
       "      <th>SLC1A3</th>\n",
       "      <th>ATP1A3</th>\n",
       "      <th>RBFOX3</th>\n",
       "      <th>GABRA4</th>\n",
       "      <th>NHSL1</th>\n",
       "      <th>GRAMD3</th>\n",
       "      <th>SEZ6L2</th>\n",
       "      <th>...</th>\n",
       "      <th>PRODH</th>\n",
       "      <th>FERMT1</th>\n",
       "      <th>CSPG4</th>\n",
       "      <th>GJA1</th>\n",
       "      <th>LAMA1</th>\n",
       "      <th>YAP1</th>\n",
       "      <th>LINC00639.2</th>\n",
       "      <th>SMOC1</th>\n",
       "      <th>LINC00498</th>\n",
       "      <th>GFRA1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.038262</td>\n",
       "      <td>161.176004</td>\n",
       "      <td>68.074337</td>\n",
       "      <td>58.063405</td>\n",
       "      <td>20.021864</td>\n",
       "      <td>269.294069</td>\n",
       "      <td>188.205520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.001093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.324867</td>\n",
       "      <td>75.256474</td>\n",
       "      <td>87.297510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.061554</td>\n",
       "      <td>342.166102</td>\n",
       "      <td>683.328784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.003420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.003420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220.143867</td>\n",
       "      <td>187.976727</td>\n",
       "      <td>42.219372</td>\n",
       "      <td>106.553653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>187.976727</td>\n",
       "      <td>299.556496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.036562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>166.010840</td>\n",
       "      <td>26.159284</td>\n",
       "      <td>61.373704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.183789</td>\n",
       "      <td>254.549955</td>\n",
       "      <td>446.720079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.153158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.006126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188.426220</td>\n",
       "      <td>71.160966</td>\n",
       "      <td>119.269788</td>\n",
       "      <td>57.129226</td>\n",
       "      <td>16.036274</td>\n",
       "      <td>265.600789</td>\n",
       "      <td>287.650666</td>\n",
       "      <td>24.054411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.002267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 608 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GABRG2       CELF4       SRRM4      SLC1A3     ATP1A3      RBFOX3  \\\n",
       "0   35.038262  161.176004   68.074337   58.063405  20.021864  269.294069   \n",
       "1   95.324867   75.256474   87.297510    0.000000  18.061554  342.166102   \n",
       "2  220.143867  187.976727   42.219372  106.553653   0.000000  187.976727   \n",
       "3  166.010840   26.159284   61.373704    0.000000  30.183789  254.549955   \n",
       "4  188.426220   71.160966  119.269788   57.129226  16.036274  265.600789   \n",
       "\n",
       "       GABRA4      NHSL1  GRAMD3     SEZ6L2  ...  PRODH  FERMT1  CSPG4  GJA1  \\\n",
       "0  188.205520   0.000000     0.0   0.000000  ...    0.0     0.0    0.0   0.0   \n",
       "1  683.328784   0.000000     0.0   1.003420  ...    0.0     0.0    0.0   0.0   \n",
       "2  299.556496   0.000000     0.0   0.000000  ...    0.0     0.0    0.0   0.0   \n",
       "3  446.720079   0.000000     0.0  25.153158  ...    0.0     0.0    0.0   0.0   \n",
       "4  287.650666  24.054411     0.0   1.002267  ...    0.0     0.0    0.0   0.0   \n",
       "\n",
       "   LAMA1  YAP1  LINC00639.2     SMOC1  LINC00498  GFRA1  \n",
       "0    0.0   0.0     0.000000  1.001093        0.0    0.0  \n",
       "1    0.0   0.0     0.000000  1.003420        0.0    0.0  \n",
       "2    0.0   0.0     7.036562  0.000000        0.0    0.0  \n",
       "3    0.0   0.0     0.000000  1.006126        0.0    0.0  \n",
       "4    0.0   0.0     0.000000  0.000000        0.0    0.0  \n",
       "\n",
       "[5 rows x 608 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "minor-image",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-eclipse",
   "metadata": {},
   "source": [
    "### Spliting the dataset for test set and train set\n",
    "\n",
    "Splitting the dataset into train set and test set, in this splitting, I used 30% of the whole data set as a test size which is a random 30% of the dataset and the other random 70% of the dataset will be used as a training set to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "drawn-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-synthetic",
   "metadata": {},
   "source": [
    "# <center> Experimental Methods and Setup <center>\n",
    " To get the best machine learning model accuracy, I am going to test the model with 3 different ntree values and \n",
    " 3 different mtry values with setting the oob_score to True. And then, I am going to compare the f1 score to choose  the best model.  \n",
    "    \n",
    " * ntree = 500, mtry = 12, oob_score = True <br><br>\n",
    "    \n",
    " * ntree = 500, mtry = 24, oob_score = True <br><br>\n",
    "    \n",
    " * ntree = 500, mtry = 49, oob_score = True <br><br>\n",
    "    \n",
    " * ntree = 1000, mtry = 12, oob_score = True <br><br>\n",
    "    \n",
    " * ntree = 1000, mtry = 24, oob_score = True <br><br>\n",
    "    \n",
    " * ntree = 1000, mtry = 49, oob_score = True <br><br>\n",
    "    \n",
    " * ntree = 5000, mtry = 12, oob_score = True <br><br>\n",
    "    \n",
    " * ntree = 5000, mtry = 24, oob_score = True <br><br>\n",
    "    \n",
    " * ntree = 5000, mtry = 49, oob_score = True <br><br>\n",
    "\n",
    "I am going to try with 9 different combination of 3 different ntree and 3 different mtry, which are 500, 1000, 5000 for ntree and 12, 24, 49 for the mtry. The different mtry values are coming from half squre root of total number of features, square root of the total number of features, and double square root of the total number of features. And then, I build the model with each combination and train the model and then calculated the f1 score for each different combination of the model. \n",
    "    \n",
    "### Comparing F1_Scores to choose the best model\n",
    "\n",
    "After getting the f1 scores, I sorted by the scores in assending order, the best f1 scores are the combination of 500 ntree, 49 mtry; 1000 ntree, 49 mtry; and 5000 ntree, 49 mtry. Since the random forest model used the random decision tree and over a 1000 tree the accuracy not become much more different, so I picked the combination of 5000 ntree and 49 mtry as the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "incorporate-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_number_of_features = np.sqrt(len(features.columns))\n",
    "m1 = int(0.5 * sqrt_number_of_features)\n",
    "m2 = int(sqrt_number_of_features)\n",
    "m3 = int(2 * sqrt_number_of_features)\n",
    "\n",
    "ntree = [500, 1000, 5000]\n",
    "mtry = [m1, m2, m3]\n",
    "f1_list = []\n",
    "\n",
    "\n",
    "# ntree 500 , mtry 12\n",
    "RF1 = RandomForestClassifier(n_estimators=ntree[0], max_features=mtry[0], oob_score=True)\n",
    "RF1.fit(x_train, y_train)\n",
    "predict1 = RF1.predict(x_test)\n",
    "f1 = f1_score(y_test, predict1, average='weighted')\n",
    "f1_list.append(f1)\n",
    "\n",
    "\n",
    "# ntree 500 , mtry 24\n",
    "RF2 = RandomForestClassifier(n_estimators=ntree[0], max_features=mtry[1], oob_score=True)\n",
    "RF2.fit(x_train, y_train)\n",
    "predict2 = RF2.predict(x_test)\n",
    "f1 = f1_score(y_test, predict2, average='weighted')\n",
    "f1_list.append(f1)\n",
    "\n",
    "\n",
    "# ntree 500 , mtry 49\n",
    "RF3 = RandomForestClassifier(n_estimators=ntree[0], max_features=mtry[2], oob_score=True)\n",
    "RF3.fit(x_train, y_train)\n",
    "predict3 = RF3.predict(x_test)\n",
    "f1 = f1_score(y_test, predict3, average='weighted')\n",
    "f1_list.append(f1)\n",
    "\n",
    "\n",
    "# ntree 1000 , mtry 12\n",
    "RF4 = RandomForestClassifier(n_estimators=ntree[1], max_features=mtry[0], oob_score=True)\n",
    "RF4.fit(x_train, y_train)\n",
    "predict4 = RF4.predict(x_test)\n",
    "f1 = f1_score(y_test, predict4, average='weighted')\n",
    "f1_list.append(f1)\n",
    "\n",
    "\n",
    "# ntree 1000 , mtry 24\n",
    "RF5 = RandomForestClassifier(n_estimators=ntree[1], max_features=mtry[1], oob_score=True)\n",
    "RF5.fit(x_train, y_train)\n",
    "predict5 = RF5.predict(x_test)\n",
    "f1 = f1_score(y_test, predict5, average='weighted')\n",
    "f1_list.append(f1)\n",
    "\n",
    "\n",
    "# ntree 1000 , mtry 49\n",
    "RF6 = RandomForestClassifier(n_estimators=ntree[1], max_features=mtry[2], oob_score=True)\n",
    "RF6.fit(x_train, y_train)\n",
    "predict6 = RF6.predict(x_test)\n",
    "f1 = f1_score(y_test, predict6, average='weighted')\n",
    "f1_list.append(f1)\n",
    "\n",
    "\n",
    "# ntree 5000 , mtry 12\n",
    "RF7 = RandomForestClassifier(n_estimators=ntree[2], max_features=mtry[0], oob_score=True)\n",
    "RF7.fit(x_train, y_train)\n",
    "predict7 = RF7.predict(x_test)\n",
    "f1 = f1_score(y_test, predict7, average='weighted')\n",
    "f1_list.append(f1)\n",
    "\n",
    "\n",
    "# ntree 5000 , mtry 24\n",
    "RF8 = RandomForestClassifier(n_estimators=ntree[2], max_features=mtry[1], oob_score=True)\n",
    "RF8.fit(x_train, y_train)\n",
    "predict8 = RF8.predict(x_test)\n",
    "f1 = f1_score(y_test, predict8, average='weighted')\n",
    "f1_list.append(f1)\n",
    "\n",
    "\n",
    "# ntree 5000 , mtry 49\n",
    "RF9 = RandomForestClassifier(n_estimators=ntree[2], max_features=mtry[2], oob_score=True)\n",
    "RF9.fit(x_train, y_train)\n",
    "predict9 = RF9.predict(x_test)\n",
    "f1 = f1_score(y_test, predict9, average='weighted')\n",
    "f1_list.append(f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-victim",
   "metadata": {},
   "source": [
    "### Comparing f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "wound-residence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500 ntree, 12 mtry</th>\n",
       "      <td>0.971571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000 ntree, 12 mtry</th>\n",
       "      <td>0.975870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000 ntree, 24 mtry</th>\n",
       "      <td>0.975870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000 ntree, 12 mtry</th>\n",
       "      <td>0.975870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000 ntree, 49 mtry</th>\n",
       "      <td>0.980437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500 ntree, 24 mtry</th>\n",
       "      <td>0.984210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000 ntree, 24 mtry</th>\n",
       "      <td>0.984210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000 ntree, 49 mtry</th>\n",
       "      <td>0.984483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500 ntree, 49 mtry</th>\n",
       "      <td>0.988262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     F1_Scores\n",
       "500 ntree, 12 mtry    0.971571\n",
       "1000 ntree, 12 mtry   0.975870\n",
       "1000 ntree, 24 mtry   0.975870\n",
       "5000 ntree, 12 mtry   0.975870\n",
       "1000 ntree, 49 mtry   0.980437\n",
       "500 ntree, 24 mtry    0.984210\n",
       "5000 ntree, 24 mtry   0.984210\n",
       "5000 ntree, 49 mtry   0.984483\n",
       "500 ntree, 49 mtry    0.988262"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'F1_Scores':f1_list}, index=[\"500 ntree, 12 mtry\", \"500 ntree, 24 mtry\", \"500 ntree, 49 mtry\",\n",
    "                                   \"1000 ntree, 12 mtry\", \"1000 ntree, 24 mtry\", \"1000 ntree, 49 mtry\",\n",
    "                                   \"5000 ntree, 12 mtry\", \"5000 ntree, 24 mtry\", \"5000 ntree, 49 mtry\"])\n",
    "df = df.sort_values(by=['F1_Scores'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-catering",
   "metadata": {},
   "source": [
    "# <center> Results of RF Training and Accuracy Estimates </center>\n",
    "\n",
    "I am choosing the ntree = 5000, mtry = 49 and oob_score=False to build the best model. \n",
    "\n",
    "And then, showing the confusion matrix, accuracy, recall, precision and f1 score. \n",
    "\n",
    "Precision is a measure of the accuracy provided that a class label has been predicted. \n",
    "It is defined by: precision = TP/(TP + FP)\n",
    "\n",
    "Recall is the true positive rate.\n",
    "It is defined as: Recall = TP/(TP + FN)\n",
    "\n",
    "Trying to compare OOB error and cross validation error by trining the model with the full dataset. \n",
    "\n",
    "Getting the values of OOB Error : 0.0161 by showing four decimal places. \n",
    "\n",
    "Getting the values of Cross Validation Error : 0.0172 by showing four decimal places. \n",
    "\n",
    "The error values are very similar but the difference is 0.0011 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "honest-attempt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_features=49, n_estimators=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=49, n_estimators=5000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_features=49, n_estimators=5000)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_Model = RandomForestClassifier(n_estimators=5000, max_features=49, oob_score=False)\n",
    "RF_Model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "alpine-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = RF_Model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "satisfactory-acquisition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9844825823061977"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = f1_score(y_test, predict, average='weighted')\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-range",
   "metadata": {},
   "source": [
    "## Perform k-fold cross-validation and obtain predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "running-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Pred = cross_val_predict(RF_Model, features, Y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "potential-peoples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 77  13]\n",
      " [  2 779]]\n"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "print(confusion_matrix(Y, Y_Pred, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "meaning-prescription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 77  13]\n",
      " [  2 779]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(Y, Y_Pred, labels=[1,0])\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(c_matrix, classes=['class=1','class=0'], normalize=False, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "persistent-polls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       781\n",
      "           1       0.97      0.86      0.91        90\n",
      "\n",
      "    accuracy                           0.98       871\n",
      "   macro avg       0.98      0.93      0.95       871\n",
      "weighted avg       0.98      0.98      0.98       871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y, Y_Pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-costume",
   "metadata": {},
   "source": [
    "### Showing OOB error from full training phase and compare it with error from CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "arctic-spouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Error :  0.0161\n",
      "CV Error:  0.0172\n"
     ]
    }
   ],
   "source": [
    "RF_OOB = RandomForestClassifier(n_estimators=5000, max_features=49, oob_score=True)\n",
    "\n",
    "RF_OOB.fit(features, Y)\n",
    "\n",
    "oob_error = 1 - RF_OOB.oob_score_\n",
    "\n",
    "print(f\"OOB Error : {oob_error: .4f}\")\n",
    "\n",
    "cv_scores = cross_val_score(RF_OOB, features, Y, cv=3)\n",
    "\n",
    "cv_error = 1 - cv_scores.mean()\n",
    "\n",
    "print(f\"CV Error: {cv_error: .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-wonder",
   "metadata": {},
   "source": [
    "# <center> Feature Ranking </center>\n",
    "\n",
    "\n",
    "The top 10 ranked features are COL5A2, COL5A2.2, COL5A2.1, NDNF.1, NDNF, NDNF.2, SST, FAT1, TOX3.1, TOX3.2 and the first rank is COL5A2 with the important value of 0.07252\n",
    "\n",
    "From the reference paper: I1 cluster: A human MTG cortical layer 1 GABAergic interneuron that selectively expresses\n",
    "COL5A2 and NDNF and FAT1 mRNAs, which is biologically developed ground truth. \n",
    "\n",
    "In the top 10 ranked features all of those three mRNAs are included and the trained model can be pretty much reliabled according to the top features ranking and its accuracy.  \n",
    "\n",
    "\n",
    "I would like to suggest to used like a least 8 or all of the top 10 features in production because in 8 out of top 10 ranked features included COL5A2, NDNF and FAT1 which are the features of biologically developed ground truth and also the more fuatures , the prediction of the model can be more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "naval-village",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COL5A2 : 0.07252\n",
      "COL5A2.2 : 0.06903\n",
      "COL5A2.1 : 0.06503\n",
      "NDNF.1 : 0.04268\n",
      "NDNF : 0.03912\n",
      "NDNF.2 : 0.03670\n",
      "SST : 0.03477\n",
      "FAT1 : 0.03124\n",
      "TOX3.1 : 0.02573\n",
      "TOX3.2 : 0.02524\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances = RF_Model.feature_importances_\n",
    "\n",
    "feature_names = features.columns\n",
    "\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "sorted_feature_importance = sorted_feature_importance[0:10]\n",
    "\n",
    "for feature, importance in sorted_feature_importance:\n",
    "    print(f\"{feature} : {importance:.5f}\")\n",
    "\n",
    "sorted_feature_importance = reversed(sorted_feature_importance)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.barh(*zip(*sorted_feature_importance))\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance in Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-macro",
   "metadata": {},
   "source": [
    "# <center> RF Run Time Test </center>\n",
    "\n",
    "I have tested with 2 random sample, one is class 1 sample and the other is class 0 sample. \n",
    "\n",
    "The prediction probabilites for sample1 are 0.122 for class 0 and 0.878 for class 1. \n",
    "\n",
    "The truth label is 1 for the sample 1 and the probability is more on class 1. \n",
    "\n",
    "The prediction probabilities for sample2 are 0.997 for class 0 and 0.003 for class 1. \n",
    "\n",
    "The truth label is 0 for the sample 2 and the probability is more on class 0. \n",
    "\n",
    "Both samples prediction are correct and the prediction probabilities for class 0 sample is a lot higher than compared with the class 1 sample precdication. \n",
    "\n",
    "In the dataset the total samples of class 0 is 781 and the total samples of class 1 is 90, so that is the reason for the prediction probabilities is more on class 0 samples and the model can be able to predict more accurate on class 0 sample than class 1 samples because the model has been trained with more class 0 samples than class 1 samples.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "mental-animal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Probabilities (0 and 1) for sample1:  [[0.122 0.878]]\n",
      "Class Probabilities (0 and 1) for sample2:  [[0.997 0.003]]\n"
     ]
    }
   ],
   "source": [
    "# label 1\n",
    "sample1 = features[403:404]\n",
    "\n",
    "# label 0\n",
    "sample2 = features[389:390] \n",
    "\n",
    "prob1 = RF_Model.predict_proba(sample1)\n",
    "\n",
    "prob2 = RF_Model.predict_proba(sample2)\n",
    "\n",
    "\n",
    "print(\"Class Probabilities (0 and 1) for sample1: \", prob1)\n",
    "print(\"Class Probabilities (0 and 1) for sample2: \", prob2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-vinyl",
   "metadata": {},
   "source": [
    "# References and resources\n",
    "\n",
    "* Jupyter\n",
    "* Python library scikit-learn, pandas, numpy, matplotlib\n",
    "\n",
    "### Papers\n",
    "\n",
    "* [Link](https://academic.oup.com/hmg/article/27/R1/R40/4953379)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-endorsement",
   "metadata": {},
   "source": [
    "### Aung Phyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-therapy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
